---
title:  "ContinualAI Reading Group"
layout: page
---

The *ContinualAI Reading Group* is hosted every Friday in collaboration with [MILA](https://mila.quebec/en/) and it is based on roughly 60 minutes discussion about a particular Continual Learning paper. Occasionally, a speaker is invited to explain his work. Join our reading group [on slack](https://join.slack.com/t/continualai/shared_invite/enQtNjQxNDYwMzkxNzk0LTBhYjg2MjM0YTM2OWRkNDYzOGE0ZTIzNDQ0ZGMzNDE3ZGUxNTZmNmM1YzJiYzgwMTkyZDQxYTlkMTI3NzZkNjU)! It will be the occasion to talk with other researchers of this amazing field!

Here is the list of the previous RG sessions:

- [\[October 16th 2020\] “Memory-Efficient Incremental Learning Through Feature Adaptation”](https://www.youtube.com/watch?v=XvhXTwqPXG0)
- [\[October 9th 2020\] “Continual Learning from the Perspective of Compression”](https://www.youtube.com/watch?v=_LGU5MBjJAQ)
- [\[October 2nd 2020\] "Bookworm Continual Learning: Beyond Zero-Shot Learning and Continual Learning"](https://www.youtube.com/watch?v=KeeX445siGg)
- [\[Sptember 25th 2020\] “A Wholistic View of Continual Learning with Deep Neural Networks”](https://www.youtube.com/watch?v=Dwlr7IsO5SI)
- [\[Sptember 11th 2020\] "GDumb: A Simple Approach that Questions Our Progress in Continual Learning"](https://youtu.be/fUW_UxCZLDA)
- [\[Sptember 4th 2020\] "Online Fast Adaptation and Knowledge Accumulation (OSAKA): a New Approach to Continual Learning"](https://www.youtube.com/watch?v=AHGiF21WZbw)
- [\[July 24th 2020\] "Efficient Continual Learning in Neural Networks with Embedding Regularization"](https://www.youtube.com/watch?v=MJC4XrmIIYI)
- [\[July 16th 2020\] "Supermasks in Superposition"](https://www.youtube.com/watch?v=TJEzwVvypOI)
- [\[July 10th 2020\] "Networks naturally learn to learn and forget to forget"](https://www.youtube.com/watch?v=nmCiDeh-lKY)
- [\[July 3rd 2020\] "Modeling the Background for Incremental Learning in Semantic Segmentation"](https://www.youtube.com/watch?v=vjyEiMYth6Y)
- [\[June 19th 2020\] “Continual Learning of Recurrent Neural Networks by Locally Aligning Distributed Representations”](https://www.youtube.com/watch?v=EWNyqWe6t10&list=PLm6QXeaB-XkBMFxvgZvYjqhaPgGg8Um9Z&index=8)
- [\[June 12th 2020\] “Learning to Recognize Code-switched Speech Without Forgetting”](https://www.youtube.com/watch?v=-gAYJvR-Hu0&list=PLm6QXeaB-XkBMFxvgZvYjqhaPgGg8Um9Z&index=7)
- [\[June 6th 2020\] “Explaining How Deep Neural Networks Forget by Deep Visualization”](https://www.youtube.com/watch?v=4cqyKoIPa8Q)
- [\[May 22th 2020\] “Small-Task Incremental Learning”](https://www.youtube.com/watch?v=9xm4P4Kss54)
- [\[May 15th 2020\] “Generative Feature Replay For Class-Incremental Learning”](https://www.youtube.com/watch?v=Lu3D2FN61Wo)
- [\[May 8th 2020\] "Defining Benchmarks for Continual Few-Shot Learning"](https://www.youtube.com/watch?v=7G9BlvodXRk)
- [\[May 1st 2020\] "Pseudo Rehearsal Using non Photo-Realistic Images"](https://www.youtube.com/watch?v=SH7IgdiH1FE)



